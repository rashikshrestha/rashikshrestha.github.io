{"posts":[{"title":"ABU Robocon 2019","text":"Our team from Pulchowk Campus, Tribhuwan University represented Nepal in the international competition ABU Robocon 2019, held at Ulaanbaatar, Mongolia. I was involved in design, fabrication and testing the two robots used for the game. I got to learn working as a team to create a greater impact. I worked on sensor calibration and modeling, kalman filters, sensor fusion, inverse kinematics and much more. I was more involved in programming the MR2 robot. Getting the robots to work on such a big scale was a big challenge for all of us. We didn’t have much funds to support our project, so we are bound to produce best results under tight budgetary constraints. Most of the expensive actuators and sensors came from previous robots, which were built for ABU robocon 2018/2017. We had major issues in circuits, as we didn’t have circuit manufactures that could deliver the circuits to us. So, all the circuits made were completely hand itched.","link":"/2020/10/07/abu-robocon-2019/"},{"title":"More on g++","text":"Introductiong++ is a tool for preprocessing, compilation, assembly and linking of source code to generate an executable file or library. InstallationAs easy as: sudo apt update sudo apt install g++ General Syntax General syntax to run g++ compiler is: g++ &lt;flags_with_params&gt; &lt;source_files&gt; The above command takes a bunch of source files along with some flags and generates an executable file or a library file. Flags are very important because they can control the way compilation occurs. For example, if we have a single source file main.cpp and need to generate an executable file named out, the basic syntax for this task is g++ main.cpp -o out Here, main.cpp is a source file and -o is a flag to specify the output filename. out is the name of the output executable file. Command can be as complex as g++ -Wall -std=c++14 -I/some/path/to/include/dir -O3 -c -fpermissive -fPIE -o objectfile.o sourcefile1.cpp sourcefile2.cpp sourcefile2.cpp -L/path/to/library/dir -lsomelibrary1 lsomelibrary2 Here, -W -std -O -c -f -o -L -l are the flags along with their parameters and sourcefile1.cpp sourcefile2.cpp sourcefile2.cpp are three source files. Some important flags -o Specifies the output filename -I Specifies the dir to look for header files -L Specifies the dir to look for libraries -l Specifies the name of a library to link to -g To enable debugging -std Specifies the C++ language standard -O Specifies the Optimization level -W Specifies the Warning option Order doesn’t matter (except in few cases) flags and source files can be written in any order. (with some exceptions while linking libraries, discussed below) Take a simple C++ code main.cpp 1234567#include &lt;iostream&gt;int main(){ std::cout &lt;&lt; &quot;Hello, world!&quot; &lt;&lt; std::endl; return 0;} Any of the following commands can be used to generate the executable file main g++ main.cpp -o main g++ -o main main.cpp g++ main.cpp -omain g++ -omain main.cpp As you can see, it doesn’t matter in what order you keep -o flag and source file main.cpp Moreover, it doen’t matter if you keep a space after -o flag or not. Now, lets add some more flags: -Wall to show all the warnings, -g to enable debugging, and -std to specify C++ standard. All the commands below produces identical output: g++ -Wall -g -std=c++14 main.cpp -o main g++ -Wall main.cpp -g -omain -std=c++14 g++ main.cpp -Wall -omain -g -std=c++14 Now, lets try this with more than one source file We can compile this with any of following commands: g++ main.cpp add.cpp subtract.cpp -o main (Simplest way) g++ -g -std=c++14 -Wall main.cpp add.cpp subtract.cpp -o main (With some flags) g++ -Wall add.cpp -std=c++14 -o main main.cpp -g subtract.cpp (Jumble up everything and it still works) Creating Library Executable file is a standalone file, which can be executed i.e run as a program. Whereas a library is a collection of stuff that can be invoked from the executable files. All the examples above show how to create an executable file. There are two types of library: Static Library Dynamic Library Creating Static Library Static library is nothing but a precompiled source file that can be linked to generate an executable file or other library. First flow chart shows how an executable is generated by processing all the source files via the whole pipeline. Second flow chart shows object files are generated in intermediate steps and are linked later to generate an executable file. These object files can be viewed as static libraries that are linked to main.o to produce an executable file. This can be done using following commands: g++ -c main.cpp add.cpp subtract.cpp (Generate Object files) g++ main.o add.o subtract.o -o main (Generate executable from object files) Moreover, we can mix up source files and object files while generating executable file: g++ -c add.cpp subtract.cpp g++ main.cpp add.o subtract.o -o main Here, add.o and subtract.o are the object files acting as library for main.cpp Now, lets try to bundle up these object files into a single file, which we can call Static Library g++ -c add.cpp subtract.cpp (first generate add.o and subtract.o) ar rc my_first_library add.o subtract.o (Bundle/Archive the object files to a single file my_first_library) g++ main.cpp my_first_library -o main (Now, use this library to produce the executable file) Thats it! You have sucessfully created and used your first Static Library. ar is called archiver. A tool used to create, modify, and extract from archives. You can see the list of files in archive using: ar -t my_first_library Still some work left … Well, now let’s look into some naming conventions and standard ways of linking a static library. Generally, static library is named as: lib&lt;library_name&gt;.a And is linked as: g++ &lt;source_files&gt; -o &lt;output_filename&gt; -L&lt;path/to/lib&gt; -l&lt;name_of_lib&gt; So, correct way of linking a static library in above example is: g++ -c add.cpp subtract.cpp (first generate add.o and subtract.o) ar rc libmy_first_library.a add.o subtract.o (Bundle/Archive the object files to a single file) g++ main.cpp -o main -L. -lmy_first_library (Now, use this library to produce the executable file) Creating Dynamic Library Dynamic library are not linked with the executable file during compilation process. They are linked during execution. i.e. linked dynamically. Dynamic library is named as: lib&lt;library_name&gt;.so Commands to create dynamic library for above example are: g++ -c add.cpp subtract.cpp (First generate object files as before) g++ -shared add.o subtract.o -o libmy_first_shared_library.so (generate a shared library form the object files) g++ main.cpp -o main -L. -lmy_first_shared_library (Now create an executable by linking the dynamic library) Now, if you run ./main, it will probably give an error. That’s because the executable main needs to know where to search for library libmy_first_shared_library.so. We can add the search path to the environment variable LD_LIBRARY_PATH so that main finds it. export LD_LIBRARY_PATH=/path/to/dynamic_library Now, when you run ./main, it should work perfectly. You can also see all the dynamic dependencies/libraries linked to main by using command ldd main. i.e. List Dynamic Dependencies of executable file main Order Matters here.. While generating the executable main by linking static or dynamic library in above example, we have used: g++ main.cpp -o main -L. -lname_of_lib But as the flags are position independent, we may try to compile with: g++ -o main -L. -lname_of_lib main.cpp But this time, it shows error stating undefined reference The source file main.cpp uses the functions add and subtract, which is found inside the linked library. g++ is designed in such a way that dependent stuff must be mentioned beforehand. As main.cpp is dependent on -lname_of_lib , main.cpp must be written before -lname_of_lib Other flags can be kept anywhere.","link":"/2022/04/05/all_about_g++/"},{"title":"CaLDiff. Camera Localization in NeRF via Pose Diffusion","text":"-&gt; Get Paper PDF &lt;--&gt; arXiv Link &lt;- With the widespread use of NeRF-based implicit 3D representation, the need for camera localization in the same representation becomes manifestly apparent. Doing so not only simplifies the localization process – by avoiding an outside-the-NeRF-based localization – but also has the potential to offer the benefit of enhanced localization. This paper studies the problem of localizing cameras in NeRF using a diffusion model for camera pose adjustment. More specifically, given a pre-trained NeRF model, we train a diffusion model that iteratively updates randomly initialized camera poses, conditioned upon the image to be localized. At test time, a new camera is localized in two steps: first, coarse localization using the proposed pose diffusion process, followed by local refinement steps of a pose inversion process in NeRF. In fact, the proposed camera localization by pose diffusion (CaLDiff) method also integrates the pose inversion steps within the diffusion process. Such integration offers significantly better localization, thanks to our downstream refinement-aware diffusion process. Our exhaustive experiments on challenging real-world data validate our method by providing significantly better results than the compared methods and the established baselines. Our source code will be made publicly available.","link":"/2023/11/07/caldiff/"},{"title":"&#39;const&#39; keyword in C++","text":"` Use Cases We basically have 3 use cases of const keyword: Restrict the change in value of a Variable Restrict the change of Pointer Restrict the class method to change the variables of that class Restrict the change in value of a Variable12const int x = 7;x = 10; // ERROR, cannot change the value of x 12const int&amp; p = 9;p = 10; // ERROR, cannot change the value of p 123456const int* a = NULL;int val = 2;a = &amp;val; // We can change the Pointer*a = 10; // ERROR, But we can’t change the contents of that Pointer Another way of writing: const int x = 7 is identical to int const x = 7 const int&amp; p = 9 is identical to int const &amp; p = 9 const int* a = NULL is identical to int const * a = NULL Generalization: const can be written on either side of datatype name (e.g. int, float, class_name etc.) in order to restrict the change in value. Restrict the change of a Pointer123456int* const a = NULL;int val = 2;a = &amp;val; // ERROR, We can't change the Pointer*a = 10; // But we can change the contents of that Pointer Restrict the class method to change the variables of that class123456789class Person{ int age=7; int modify_age() const { age = 10; // ERROR, const method cannot modify class variables }}; Combining all three12345678910class Dummy{ int* ptr = NULL; const int* const get_ptr() const { return ptr; }}; get_ptr is a constant method which cannot change the variables of that class and returns a pointer which cannot be changed nor can be its content. const int* const get_ptr() const is identical to int const * const get_ptr() const Second one seems more uniform as const always appear on the right side of what it is applied on. That is: int const makes value const * cont makes pointer const get_ptr() const makes method const TODOvoid function_name(const int x) const objects can call const methods only12345678910111213141516171819202122232425class Person{private: int age = 7;public: int get_age() const { return age; } void set_age(int val) { age = val; }};int main(){ const Person p; p.get_age(); // Works fine p.set_age(10); // ERROR, const object p can only call const methods return 0;}","link":"/2022/12/08/const-keyword-in-cpp/"},{"title":"Sign Language gestures to Speech Gloves","text":"This glove can convert sign language gestures to actual speech. It uses 9 axis motion data (accelerometer, gyroscope and magnetometer) to estimate the orientation of the hand, along with one flex sensor on each finger to detect the bendings. The microprocessor used on the gloves then translates the data to the English language and sends it to a custom application on a mobile phone. The app then dictates the received text. This project was done as a part of a hardware hackathon held on Thapathali Campus (Institute of Engineering) and was completed in the time frame of 1 week. The signs used were arbitrary, but can be updated to use standard ones.","link":"/2019/12/09/gesture_to_speech/"},{"title":"ML model visualization using Netron","text":"1. Intro Netron is really great tool to visualize the ML models. ONNX (Open Neural Network Exchange Format) is a format designed to represent any type of Machine Learning and Deep Learning models. Pytorch and Tensorflow can export the model in onnx format. This onnx file can then be read with Netron to visualize the model graphically. 2. InstallationAs simple as: 1pip install netron 3. Barebone code123456789101112131415161718192021222324252627import torchimport torch.nn as nnimport netron# Define the Modelclass NeuralNetwork(nn.Module): def __init__(self): super(NeuralNetwork, self).__init__() self.flatten = nn.Flatten() self.dense1 = nn.Sequential( nn.Linear(28*28, 512), nn.ReLU(), nn.Linear(512, 10), nn.ReLU() ) def forward(self, x): x = self.flatten(x) out = self.dense1(x) return outmodel = NeuralNetwork() # Create a Modeldummy_input = torch.ones([1,28,28]) # Dummy Input to the model # (batch_size=1, input_shape=(28x28))model_path = &quot;simple_model.onnx&quot; # Path of the onnx filetorch.onnx.export(model, dummy_input, model_path) # Export the model to ONNX filenetron.start(model_path) # Visualize using Netron Output Above code will open the visualization in browser @ http://localhost:8080/ It needs a dummy input to pass through the model and calculate necessary data. Dummy input can be anything. It just needs to have right shape that model takes. To name the inputs and outputs, add following parameters to the torch.onnx.export function. 123torch.onnx.export(model, dummy_input, model_path, input_names = ['image'], output_names = ['prediction']) 4. Show tensor shapes at each step Install onnx package1pip install onnx After exporting the onnx file, read back using onnx.load and then infer the tensor shapes1234# Input tensor shapes at each steponnx.save(onnx.shape_inference.infer_shapes(onnx.load(model_path)), model_path)netron.start(model_path) # Visualize using Netron Output This is a lot better visualization of model 5. Multiple Inputs Outputs Here is example using Two inputs and Two outputs123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960import torchimport torch.nn as nnimport netronimport onnx# Define the Modelclass NeuralNetwork(nn.Module): def __init__(self): super(NeuralNetwork, self).__init__() self.flatten = nn.Flatten() self.dense1 = nn.Sequential( nn.Linear(28*28, 512), nn.ReLU(), nn.Linear(512, 10), nn.ReLU() ) self.dense2 = nn.Sequential( nn.Linear(14*14, 256), nn.ReLU(), nn.Linear(256, 10), nn.ReLU() ) self.head1 = nn.Sequential( nn.Linear(20,10), nn.ReLU() ) self.head2 = nn.Sequential( nn.Linear(20,15), nn.ReLU(), nn.Linear(15,10), nn.ReLU() ) def forward(self, x, y): x_out = self.flatten(x) y_out = self.flatten(y) x_out = self.dense1(x_out) y_out = self.dense2(y_out) combined = torch.cat((x_out,y_out),1) pred1 = self.head1(combined) pred2 = self.head2(combined) return pred1, pred2model = NeuralNetwork() # Create a Modeldummy_input1 = torch.ones([1,28,28]) # Dummy Input (batch_size=1, input_shape=(28x28))dummy_input2 = torch.ones([1,14,14]) # Dummy Input (batch_size=1, input_shape=(14x14))model_path = &quot;simple_model.onnx&quot; # Path of the onnx filetorch.onnx.export(model, (dummy_input1, dummy_input2), model_path, input_names = ['image1', 'image2'], output_names = ['prediction1', 'prediction2']) # Export the model to ONNX file# Input tensor shapes at each steponnx.save(onnx.shape_inference.infer_shapes(onnx.load(model_path)), model_path)netron.start(model_path) # Visualize using Netron Output","link":"/2022/09/30/ml-model-visualization-using-netron/"},{"title":"Perspective-n-Point(PnP)","text":"Full Article Here Try this interactive plot","link":"/2023/10/19/pnp/"},{"title":"Pointers and References","text":"Memory In the context of this tutorial, memory is simply a place/register/space in our RAM where variables are stored. PointersIntroduction A pointer is just a Number (integer) that holds memory address of another variable. Size of this number/integer is not fixed. It depends upon OS, CPU architecture etc. For example, 4 bytes for 32 bit system and 8 bytes for 64 bit system. Adding &amp; in front of a vaiable name gives the address in memory where that variable is stored in. In other words, adding &amp; before variable name gives pointer to that variable. 12345678910111213#include &lt;iostream&gt;#define PRINT(msg) std::cout &lt;&lt; msg &lt;&lt; std::endlint main(){ bool x; PRINT(&amp;x); int y; PRINT(&amp;y); double z; PRINT(&amp;z);} Output 1230x7fffa8b8fc5b0x7fffa8b8fc5c0x7fffa8b8fc60 Here, 0x7fffa8b8fc5b is the memory address where variable x is kept at and similar for variables y and z. We can also define a pointer variable to store this address of x:123void* ptr;ptr = &amp;x;PRINT(ptr); Output10x7fffe596ff7c Here, pointer variable ptr is defined as void* ptr. But what does void* term actually mean? Well, the following section explain about this is detail. Type of Pointer Can a pointer have type? In above example pointers to bool x, int y and double z all looks similar. Indeed, that are same. Value of each of them is 8 byte integer (for 64 bit system). No matter which variable is it pointing, its value is always 8 byte integer. One difference we can notice is, the increment in memory address from x to z is not same. There is increment of 1 between x and y. And increment of 4 between y and z. This is because x is a bool variable which takes 1 bytes of space and y is int variable which takes 4 bytes of space in memory. Basically, &amp;x is the memory address of first byte where x is stored. And, &amp;y is the memory address of first byte where y is stored. Similar for &amp;z. Note: Variables may not be stored consequiteley in the memory So, the pointer variable which is pointing to the first byte of integer can be referred to as integer pointer. Similar for other variables. void* used in above example is pointer without any specific type. Lets clear this once again. From the perspective of a CPU, all pointers are treated the same. We just assign the different types to pointers such as bool*, int*, float* etc for the ease of use. One advantage is to know which datatype is the given pointer variable pointing to. Another advantage is in Pointer Arthematic. Which is explained in following sections. Type of pointer also comes in handy when we assign specific value to the variable pointed by that pointer.12345int x = 7;int* ptr = &amp;x;PRINT(*ptr);*ptr = 10;PRINT(*ptr); Output12710 Here, we were able to assign value 10 to int* ptr because we told compiler that ptr holds the variable of type int.:w Pointer Arthematic We have int* ptr. What might happen if we try to increment it (i.e. ptr++)? Lets Try:1234567int x = 1;int* ptr = &amp;x;PRINT(ptr);ptr++;PRINT(ptr);ptr++;PRINT(ptr); Output1230x7ffd7a7be02c0x7ffd7a7be0300x7ffd7a7be034 How about using bool*1234567bool x = 1;bool* ptr = &amp;x;PRINT(ptr);ptr++;PRINT(ptr);ptr++;PRINT(ptr); Output1230x7fff91543a1f0x7fff91543a200x7fff91543a21 Noticed the difference between incrementing int* and bool*? Pointer values are incremented by 4 for int* and by 1 for bool* That is obviously because size of int is 4 bytes and bool is 1 byte. This type of increment was possible because we specified a TYPE to the pointer. Accessing uninitialized pointers Rule is: Never try to read or write the address pointed by uninitialized pointers Uninitialized pointer variabes will hold random value which points to random section of memory. And if that section is not readable or writable, the program crashes ! 123int* ptr; // Here ptr is uninitializedPRINT(ptr); // Lets see what random value it holds*ptr = 7; // Trying to write to that random adderss crashes the program ! Output 120x55f2be742140Segmentation fault (core dumped) NULL Pointer Can be null (TODO) More on Pointers Pointer can hold memory address of variable stored in Stack or in Heap. See more about this here. ReferencesIntroduction References are like a disguised version of Pointers. References are like the nickname/alias given to a variable’s Pointer. References themselves are not new variables. They don’t occupy space in the memory. They are just there in our source code to make our work easier. They just “refer” to the existing variable.123int x = 7;int&amp; reference_to_x = x;PRINT(reference_to_x); Output17 Here, we have created a reference to the variable x. Note: &amp; used here has different meaning than that of &amp; used as address of operator ! And now we can use this term reference_to_x as if it was x. But what’s fun in that? Why do we even need reference_to_x when we can directly use x? Pass by Value vs Pointer vs ReferencePass by Value1234567891011void add_one(int val){ val += 1;}int main(){ int x = 7; add_one(x); PRINT(x);} Output 17 Here, add_one function copies the int value passed into it and increments the duplicate value. So, x remains unchanged. Pass by Pointer1234567891011void add_one(int* val){ (*val) += 1;}int main(){ int x = 7; add_one(&amp;x); PRINT(x);} Output 18 Here, the memory address of x is passed. add_value duplcates the memory address passed into it, but it still points to the same value x Then inreasing *val increases the value in x too. Pass by Reference1234567891011void add_one(int&amp; val){ val += 1;}int main(){ int x = 7; add_one(x); PRINT(x);} Output 18 This code looks exactly similar to that in Pass by Value, except one little &amp; after int in add_one function. This behaves exactly as Pass by Pointer but look much pleasing to read and write. It’s just syntatic sugar !! Criteria of using References (TODO) Must be initialized Cannot be reassigned!","link":"/2022/09/30/pointers-and-references/"},{"title":"Residual Learning for Image Point Descriptors","text":"-&gt; Get Paper PDF &lt;--&gt; arXiv Link &lt;- Local image feature descriptors have had a tremendous impact on the development and application of computer vision methods. It is therefore unsurprising that significant efforts are being made for learning-based image point descriptors. However, the advantage of learned methods over handcrafted methods in real applications is subtle and more nuanced than expected. Moreover, handcrafted descriptors such as SIFT and SURF still perform better point localization in Structure-from-Motion (SfM) compared to many learned counterparts. In this project, we propose a very simple and effective approach to learning local image descriptors by using a hand-crafted detector and descriptor. Specifically, we choose to learn only the descriptors, supported by handcrafted descriptors while discarding the point localization head. We optimize the final descriptor by leveraging the knowledge already present in the handcrafted descriptor. Such an approach of optimization allows us to discard learning knowledge already present in non-differentiable functions such as the hand-crafted descriptors and only learn the residual knowledge in the main network branch. This offers 50X convergence speed compared to the standard baseline architecture of SuperPoint while at inference the combined descriptor provides superior performance over the learned and hand-crafted descriptors. This is done with minor increase in the computations over the baseline learned descriptor. Our approach has potential applications in ensemble learning and learning with non-differentiable functions. We perform experiments in matching, camera localization and Structure-from-Motion in order to showcase the advantages of our approach.","link":"/2022/10/07/residual-feature-learning/"},{"title":"Precision Livestock Farming","text":"Click here for Project Slides Nepal is an agricultural country. Livestock farming is an integral part of the agricultural production system in Nepal, providing draft power for human consumption, fertilizers and high-value animal proteins such as meat, milk and eggs, which account for approximately 32% of agricultural GDP. Poultry farming is one of the rapidly growing business sectors in nepal. However, due to insufficient knowledge and training, farmers sometimes need to bear huge losses. Chickens, specially the boilers, have precarious health as they are highly susceptible to slight changes in their environmental factors like temperature and humidity. Considering this in mind, me and my group made a prototype system that can automate most of the critical work for farmers. It is very difficult to track and regulate the temperature, humidity and lighting manually, which can easily be automated using simple sensors and some actuators. We’ve created a sensor based feedback system which continuously regulates the environment giving them the most congenial environment to grow properly. Moreover, we’ve also implemented a camera based hen tracking system to analyze their distribution and mobility patterns. The lethargic behavior of hens can easily be detected and appropriate remedies can be taken in time to avoid future losses. All the systems can easily be monitored and controlled by farmers using a simple mobile application, which any farmer who knows how to use facebook, can understand and operate easily. We’ve presented this project idea on one of the most reputed national level hardware design competition LOCUS, and succeeded to achieve the best Hardware Design Award.","link":"/2020/05/12/precision-livestock-farming/"},{"title":"Low Cost Spin Coater","text":"Spin coating is a laboratory method to generate thin and homogeneous organic films out of solutions. An excess amount of solution is placed on an ultraporous substrate that is then rotated at high speed. The liquid spreads due to centrifugal forces and a uniform liquid layer forms on the substrate. A machine used for spin coating is called a spin coater. Though vital laboratory equipment for disease diagnosis, a commercial spin coater is pretty expensive. The cheapest one costs around 150-200 dollars, which is still unaffordable for health clinics and hospitals in rural areas of Nepal. With the help of research labs at RECAST, we developed a high speed (up to 5000 RPM) speed coater prototype with variable speed which could be used for thin fluid coating of the samples. The prototype was developed at one-tenth the cost of a commercial one. Our design showed more or less comparable results to that of commercial ones.","link":"/2018/12/09/spin_coater/"},{"title":"Steps of C++ codes compilation","text":"g++ vs gcc g++ can compile any .c or .cpp files but they will be treated as C++ files only gcc can compile any .c or .cpp files but they will be treated as C and C++ respectively Using g++ to link the object files, files automatically links in the std C++ libraries. gcc does not do this. CompilationSuppose we have simplest code in main.cpp file, then 12345g++ main.cpp # Produces the executable file (with default name i.e a.out)./a.out # Runs a.outg++ main.cpp -o main # Specifies a filename to output rather than default name./main # Runs main Not a Single Step Process! Word Compilation is using wrongly. Compilation is just Step 2 of the complete pipeline below. Barebone Source file1234567#define LUCKY_NUMBER 7int main(){ int num = LUCKY_NUMBER; return 0;} Step 1: Preprocessingg++ -E main.cpp Outputs: 12345678910111213# 1 &quot;main.cpp&quot;# 1 &quot;&lt;built-in&gt;&quot;# 1 &quot;&lt;command-line&gt;&quot;# 1 &quot;/usr/include/stdc-predef.h&quot; 1 3 4# 1 &quot;&lt;command-line&gt;&quot; 2# 1 &quot;main.cpp&quot;int main(){ int num = 7; return 0;} Step 2: Compilationg++ -S main.cpp Outputs: main.s 123456789101112131415161718192021222324252627282930313233343536373839 .file &quot;main.cpp&quot; .text .globl main .type main, @functionmain:.LFB0: .cfi_startproc endbr64 pushq %rbp .cfi_def_cfa_offset 16 .cfi_offset 6, -16 movq %rsp, %rbp .cfi_def_cfa_register 6 movl $7, -4(%rbp) movl $0, %eax popq %rbp .cfi_def_cfa 7, 8 ret .cfi_endproc.LFE0: .size main, .-main .ident &quot;GCC: (Ubuntu 9.3.0-17ubuntu1~20.04) 9.3.0&quot; .section .note.GNU-stack,&quot;&quot;,@progbits .section .note.gnu.property,&quot;a&quot; .align 8 .long 1f - 0f .long 4f - 1f .long 50: .string &quot;GNU&quot;1: .align 8 .long 0xc0000002 .long 3f - 2f2: .long 0x33: .align 84: Step 3: Assembleg++ -c main.cpp Outputs: main.oIt’s a binary file, so we cannot read it. Step 4: Linkingg++ main.cpp Outputs: a.out which is executable. Using Multiple filesTake following 3 files: 1234567891011121314151617// main.cpp#include &lt;iostream&gt;#include &quot;add.h&quot;int main(){ std::cout &lt;&lt; add(2,3) &lt;&lt; std::endl; return 0;}// --------------------------------------// add.hint add(int, int);// --------------------------------------// add.cppint add(int x, int y){ return x+y;} 12345g++ main.cpp add.cpp -o main # Generates executable file 'main' which outputs 5 when executed# OR do it in stepsg++ -c main.cpp add.cpp # Genetates two object codes 'main.o' and 'add.o'g++ main.o add.o -o main # Generates executable file 'main' which outputs 5 when executed","link":"/2022/09/30/steps-of-cpp-codes-compilation/"},{"title":"Streetfood Vending Machine","text":"Chatpate and Panipuri is one of the most popular street foods in Nepal. With a team of mechanical and electrical engineers, we developed a fully automated vending machine for it. The machine needs to be fed with raw materials once every morning, and it can work autonomously for the entire day. It can prepare customized orders from customers and accepts e-payments. For the first time, I was involved in designing and fabrication of something marketable, rather than just a college project. So, I got to learn how to make the systems robust and fail proof both electronically and programmatically. Also, we need to keep food hygiene in mind while designing the system. . The research and development of this product took almost 6 months. It took a number of prototypes and failed ideas to get to our final design, which was then launched with the name Pani Puri Bar at Kapan, Kathmandu.","link":"/2020/04/09/streetfood_vending_machine/"},{"title":"Vehicle Traffic Management and Analysis","text":"-&gt; Get full project report Here &lt;- Traffic Jams have been a major problem in Kathmandu valley especially at traffic junctions and crossroads. This requires an efficient traffic management system to be implemented at such places. But, traffic lights at most road intersections operate on a fixed timing schedule that leads to unnecessary delays, deadlock situations and moreover lead to higher fuel consumption. Our goal is to design a system which can detect the flow of traffic across those junctions, analyze those data and design an optimal traffic light sequence that can best counteract that situation. The street lighting system is based upon the electronic controller that utilizes the traffic density survey data. Data was collected and analyzed at different busy junctions of Kathmandu Valley. Cameras were used to capture video of the specific junction at various times, which was then processed to get the vehicle flow of the corresponding time. The data gives an insight into the number of vehicles entering the junction and the time required for them to cross it. For the purpose of testing the efficiency of the timing sequence generated by processing the data collected, the simulation software PTV Vissim was used. Which is a microscopic multimodal traffic flow simulation software. We also developed a prototype traffic light controller for the demonstration. This prototype can show synchronization in traffic signals on the basis of live feed from the cameras. All the systems can be monitored and even manually controlled via an easy web based interface.","link":"/2020/10/07/vehicle-traffic-management/"},{"title":"Visual SLAM for Mobile Robot in a dynamic environment","text":"-&gt; Get full project report Here &lt;- Robot localization is an integral part in mobile robotics. It is the base for path planning and navigation tasks for robots and for AR/VR applications as well. SLAM has been a well known method for mapping the unknown environment and localizing yourself in the map. Visual SLAM, the category of SLAM, makes the use of visual sensors such as cameras to perform SLAM. Such visual sensors are available at cheap cost nowadays and hence it is one of the most researched and popular topics in mobile robotics. This project uses a camera as its only sensor to build a 3d map of the entire room and localize itself in the built map. The map can then be used for navigation purposes within the mapped environment. Problems such as dynamically changing environment, varying lighting conditions, lack of textured environment are the hindrances for visual SLAM. Some of these problems have been well tackled in this project. Dynamic objects in the environment have been masked to minimize its effect. Light invariant feature extraction has been used to tackle variations in lightning conditions. The Robot Operating System (ROS) has been used to communicate between various parallel processes and between robot and PC. Most of the high computational tasks have been done on the PC. The robot then responds on the basis of commands given by processes which are running on PC.","link":"/2021/10/07/visual-localization/"}],"tags":[{"name":"C++","slug":"C","link":"/tags/C/"},{"name":"Python","slug":"Python","link":"/tags/Python/"},{"name":"ML","slug":"ML","link":"/tags/ML/"},{"name":"Photogrammetry","slug":"Photogrammetry","link":"/tags/Photogrammetry/"}],"categories":[{"name":"Project","slug":"Project","link":"/categories/Project/"},{"name":"KnowledgeBase","slug":"KnowledgeBase","link":"/categories/KnowledgeBase/"},{"name":"Publication","slug":"Publication","link":"/categories/Publication/"}],"pages":[{"title":"","text":"Bio -&gt; Google Scholar-&gt; Get my CV My research interest lies in the intersection of Robotics and Spatial Intelligence. I am facinated by how human brains can percieve the 3D environment and act accordingly. My long-term research goal is to develop a robotic system that can accurately perceive, reason about, and interact with its surrounding 3D environment. I am currently working as a Graduate Research Assistant at Interactive Robotics Laboratory, WVU under the supervision of Prof. Yu Gu. My current work focuses on accurate pose estimation of flowers followed by plant aware manipulation for precision pollination. My previous works at NAAMII under the supervision of Dr. Danda Pani Paudel and Prof. Francois Rameau, focused on leveraging the power of NeRFs and diffusion models for robust camera pose estimation in low-textured environments. I have also worked on developing hybrid (handcrafted + learned) image point descriptors for lightweight detection and matching, under the supervision of Dr. Ajad Chhatkuli.","link":"/index.html"},{"title":"Curriculum Vitae","text":"-&gt; Get my full CV Here &lt;-","link":"/cv/index.html"},{"title":"Experiences","text":"Fourth Annual Nepal AI School - Teaching Assistant Third Annual Nepal AI School - Teaching Assistant","link":"/experiences/index.html"}]}